{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pt-tweets-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/ZUmqefstmpCu1WprESKV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elisasmenendez/ds-tweet-sentiment/blob/master/classifier/pt_tweets_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHO1yD1fLXBl",
        "colab_type": "text"
      },
      "source": [
        "# Data Science Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQxl-E7LLQ46",
        "colab_type": "text"
      },
      "source": [
        "The test consists of creating a tweet dashboard to showcase text mining, data visualization, statistical analysis and development skills.\n",
        "\n",
        "* The app needs to stream tweets written in Portuguese from twitter API .\n",
        "* The app needs to classify tweet sentiment.\n",
        "  * Example classes are positive and negative denoting the tweet sentiment, but feel free to add more classes as you see fit.\n",
        "* The app needs to show tweets being classified in real-time in a dashboard.\n",
        "* The classifier must be written in Python, as it is our language of choice regarding data science. The rest can be written in your language of choice.\n",
        "* Feel free to use python libraries, no need to write things from scratch.\n",
        "* Accuracy report\n",
        "  * What metric are you using? Why ?\n",
        "  * Which type of test did you choose ?\n",
        "  * Include the test dataset.\n",
        "* Your code need to be on your GitHub profile.\n",
        "\n",
        "Bonus points if you do the following:\n",
        "\n",
        "* Dashboard with metrics (e.g. charts with tweet sentiment, time series, etc etc).\n",
        "* Your code is scalable.\n",
        "* Your code is hosted on a Cloud provider.\n",
        "* Your code runs inside docker containers, bonus points if running inside a Kubernetes Cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6N0HksrOfB8",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLKpXp1r9Fel",
        "colab_type": "text"
      },
      "source": [
        "First, let's do some imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1ETXVxIBJsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "383a5d88-d033-4dc1-cdb9-1a87cd7d0c38"
      },
      "source": [
        "import glob\n",
        "import pandas as pd \n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
        "\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60PnDTKtAb_v",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpK1eDMbp3H-",
        "colab_type": "text"
      },
      "source": [
        "We chose the dataset proposed by Brum and Nunes (2017), since it is the larger manually anotated corpus in Portuguese, considering the 3-polarity classification: negative, positive and neutral. Although the dataset is not public available (due to Twitter Privacy Policy), you can contact the first author to get the original dataset. For further references check: http://bitbucket.org/HBrum/tweetsentbr/ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86jVGH6j8odh",
        "colab_type": "text"
      },
      "source": [
        "Once you get the dataset, just drag-and-drop to the Google Colab folder on the left menu for temporary use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4keolZycLDvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load all files into a single DataFrame (positive, negative and neutral)\n",
        "all_files = glob.glob(\"tweets*\") \n",
        "df_files = (pd.read_fwf(f, header=None) for f in all_files)\n",
        "df1 = pd.concat(df_files, ignore_index=True)\n",
        "df1.rename(columns = {0: 'id', 1: 'tweet'}, inplace=True)\n",
        "\n",
        "# Load the evaluation from a separate file\n",
        "df2 = pd.read_csv('tweetSentimentBR.txt', sep='\\t', header=None)\n",
        "df2.rename(columns = {0: 'id', 1: 'hashtag', 2: 'evaluations', 4:'sentiment'}, inplace=True)\n",
        "\n",
        "# Merge both data frames by the tweet ID\n",
        "df = pd.merge(df1, df2, on='id')\n",
        "df = df[['id','tweet','hashtag','evaluations','sentiment']]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68UxneOljLGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "15dc48d6-98c8-4d0e-a354-76c519474918"
      },
      "source": [
        "df[['tweet','sentiment']]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tô passada com esse cara quanta merda pode sai...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>coitada da namorada</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>esse japa não entendi porra nenhuma de orquíde...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aí vc fica até NUMBER assistindo e acorda cedo...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>imagina que insuportável ter de dar de comer p...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>lazaro falou bale fitness e ana maria braga es...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>simpatia na trama das seis ingrid guimarães mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>ocidentais tem mta dificuldade pra aceitar com...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>USERNAME que horas vc chega em belém / aeropor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14999</th>\n",
              "      <td>não dou conta de cozinhar com apenas minha esp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet sentiment\n",
              "0      tô passada com esse cara quanta merda pode sai...        -1\n",
              "1                                    coitada da namorada        -1\n",
              "2      esse japa não entendi porra nenhuma de orquíde...        -1\n",
              "3      aí vc fica até NUMBER assistindo e acorda cedo...        -1\n",
              "4      imagina que insuportável ter de dar de comer p...        -1\n",
              "...                                                  ...       ...\n",
              "14995  lazaro falou bale fitness e ana maria braga es...         0\n",
              "14996  simpatia na trama das seis ingrid guimarães mo...         0\n",
              "14997  ocidentais tem mta dificuldade pra aceitar com...         0\n",
              "14998  USERNAME que horas vc chega em belém / aeropor...         0\n",
              "14999  não dou conta de cozinhar com apenas minha esp...         0\n",
              "\n",
              "[15000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1b2DZ4-Pl2y",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK8X-RXRPGR2",
        "colab_type": "text"
      },
      "source": [
        "We first execute some basic pre-processing steps: removing punctuation, urls and stop words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AF3hOFsR6sC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_tweet_text(tweet):\n",
        "    # remove urls\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet.lower())\n",
        "\n",
        "    # remove punctuations (fastest way)\n",
        "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
        "    \n",
        "    return tweet\n",
        "\n",
        "tweets = df['tweet'].apply(preprocess_tweet_text)\n",
        "classes = df['sentiment']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9bSyer4-l7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(nltk.corpus.stopwords.words('portuguese'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6NnZvKi99xM",
        "colab_type": "text"
      },
      "source": [
        "# Pipeline, Tests and Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n324aDKhO4OF",
        "colab_type": "text"
      },
      "source": [
        "Here, we create a pipeline to run and evaluate our classifier. \n",
        "<br><br>\n",
        "About testing: we chose the K-fold Cross-validation method (cross_val_predict), since it runs k tests by randomly spliting the dataset in multiple test and training parts, which gives a better indication of how the model would peform on unseen data.\n",
        "<br><br>\n",
        "About metrics: the classification report shows several metrics, such as, precision, recall and F-measure. However, we chose the average F-measure as our main evaluation metric since it combines both precision and recall together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muj1I4em6slw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiments=['negative','neutral','positive']\n",
        "def run_pipeline(pipeline, tweets, classes):\n",
        "  pipeline.fit(tweets,classes)\n",
        "  results = cross_val_predict(pipeline, tweets, classes, cv = 10)\n",
        "  print(classification_report(y_true=classes, y_pred=results, target_names=sentiments))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NT5Lu8rnQvX",
        "colab_type": "text"
      },
      "source": [
        "# Classifier - Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gafV_K2FPN09",
        "colab_type": "text"
      },
      "source": [
        "We start with a simple Naive Bayes classifier and try different combinations of Tokenizers (e.g. Word vs. Tweet) and Vectorizers (Count vs. TF-IDF). The results showed that is no significant difference between a simple word tokenizer and tweet specific tokenizer. Moreover, it also showed that the simple Count vectorizer performs better than the TF-IDF vectorizer.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elDBFn61ogBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa9ba5bb-3490-4e85-82dd-eaf83743e802"
      },
      "source": [
        "print(\"------ Pipeline: Word Tokenizer and Count Vectorizer ------\\n\")\n",
        "pipeline = Pipeline([\n",
        "  ('counts', CountVectorizer(analyzer=\"word\", tokenizer=word_tokenize, stop_words=stop_words)),\n",
        "  ('classifier', MultinomialNB())\n",
        "])\n",
        "run_pipeline(pipeline, tweets, classes)\n",
        "\n",
        "print(\"------ Pipeline: Word Tokenizer and Tfidf Vectorizer ------\\n\")\n",
        "pipeline = Pipeline([\n",
        "  ('counts', TfidfVectorizer(analyzer=\"word\", tokenizer=word_tokenize, stop_words=stop_words)),\n",
        "  ('classifier', MultinomialNB())\n",
        "])\n",
        "run_pipeline(pipeline, tweets, classes)\n",
        "\n",
        "print(\"------ Pipeline: Tweet Tokenizer and Count Vectorizer ------\\n\")\n",
        "tweet_tokenizer = TweetTokenizer() \n",
        "pipeline = Pipeline([\n",
        "  ('counts', CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize, stop_words=stop_words)),\n",
        "  ('classifier', MultinomialNB())\n",
        "])\n",
        "run_pipeline(pipeline, tweets, classes)\n",
        "\n",
        "print(\"------ Pipeline: Tweet Tokenizer and Tfidf Vectorizer ------\\n\")\n",
        "tweet_tokenizer = TweetTokenizer() \n",
        "pipeline = Pipeline([\n",
        "  ('counts', TfidfVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize, stop_words=stop_words)),\n",
        "  ('classifier', MultinomialNB())\n",
        "])\n",
        "run_pipeline(pipeline, tweets, classes)\n",
        "\n",
        "print(\"------ Pipeline: Word Tokenizer and Count Vectorizer + Ngrams ------\\n\")\n",
        "pipeline = Pipeline([\n",
        "  ('counts', CountVectorizer(ngram_range = (1, 2), stop_words=stop_words)),\n",
        "  ('classifier', MultinomialNB())\n",
        "])\n",
        "run_pipeline(pipeline, tweets, classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ Pipeline: Word Tokenizer and Count Vectorizer ------\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.62      0.69      0.65      4426\n",
            "     neutral       0.55      0.31      0.40      3926\n",
            "    positive       0.69      0.81      0.75      6648\n",
            "\n",
            "    accuracy                           0.65     15000\n",
            "   macro avg       0.62      0.61      0.60     15000\n",
            "weighted avg       0.63      0.65      0.63     15000\n",
            "\n",
            "------ Pipeline: Word Tokenizer and Tfidf Vectorizer ------\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.67      0.60      0.63      4426\n",
            "     neutral       0.64      0.19      0.29      3926\n",
            "    positive       0.61      0.91      0.73      6648\n",
            "\n",
            "    accuracy                           0.63     15000\n",
            "   macro avg       0.64      0.56      0.55     15000\n",
            "weighted avg       0.64      0.63      0.59     15000\n",
            "\n",
            "------ Pipeline: Tweet Tokenizer and Count Vectorizer ------\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.62      0.69      0.65      4426\n",
            "     neutral       0.55      0.31      0.40      3926\n",
            "    positive       0.69      0.81      0.75      6648\n",
            "\n",
            "    accuracy                           0.65     15000\n",
            "   macro avg       0.62      0.60      0.60     15000\n",
            "weighted avg       0.63      0.65      0.63     15000\n",
            "\n",
            "------ Pipeline: Tweet Tokenizer and Tfidf Vectorizer ------\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.67      0.60      0.63      4426\n",
            "     neutral       0.64      0.19      0.29      3926\n",
            "    positive       0.61      0.91      0.73      6648\n",
            "\n",
            "    accuracy                           0.63     15000\n",
            "   macro avg       0.64      0.56      0.55     15000\n",
            "weighted avg       0.64      0.63      0.59     15000\n",
            "\n",
            "------ Pipeline: Word Tokenizer and Count Vectorizer + Ngrams ------\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.62      0.64      0.63      4426\n",
            "     neutral       0.57      0.25      0.35      3926\n",
            "    positive       0.64      0.84      0.73      6648\n",
            "\n",
            "    accuracy                           0.63     15000\n",
            "   macro avg       0.61      0.58      0.57     15000\n",
            "weighted avg       0.62      0.63      0.60     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryEt2IIiL0zg",
        "colab_type": "text"
      },
      "source": [
        "# Classifier - Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6Fq_D3zExVd",
        "colab_type": "text"
      },
      "source": [
        "The authors in (Brum and Nunes, 2017) performed a prelimary testing in their dataset, which showed that the Logistic Regression algorithm had the best performance results. Hence, we chose this approach as our final classifier, using Word tokenizer and Count Vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OajD09waMbf2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "bc94382c-5885-4872-efaf-712a4b7d4cc9"
      },
      "source": [
        "print(\"------ Pipeline: LBFGS Solver ------\\n\")\n",
        "pipeline = Pipeline([\n",
        "  ('counts', CountVectorizer(analyzer=\"word\", tokenizer=word_tokenize, stop_words=stop_words)),\n",
        "  ('classifier', LogisticRegression(solver='lbfgs', max_iter=300))\n",
        "])\n",
        "run_pipeline(pipeline, tweets, classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ Pipeline: LBFGS Solver ------\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.65      0.63      0.64      4426\n",
            "     neutral       0.51      0.48      0.49      3926\n",
            "    positive       0.73      0.77      0.75      6648\n",
            "\n",
            "    accuracy                           0.65     15000\n",
            "   macro avg       0.63      0.63      0.63     15000\n",
            "weighted avg       0.65      0.65      0.65     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F54jxVGRkiT5",
        "colab_type": "text"
      },
      "source": [
        "# Saving the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3pw0GJAGeWV",
        "colab_type": "text"
      },
      "source": [
        "Now, after our experiments, we can train the Logistic Regression algorithm using all the dataset and save the model and the vectorizer to use in the tweet sentiment analysis task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3cMu87Oknsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=word_tokenize, stop_words=stop_words)\n",
        "freq_tweets = vectorizer.fit_transform(tweets,)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utJoGvhmmLDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier =  LogisticRegression(solver='lbfgs', max_iter=300)\n",
        "classifier.fit(freq_tweets,classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwwpsq5SuCX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(vectorizer, open('vectorizer.sav', 'wb'))\n",
        "pickle.dump(classifier, open('classifier_regression.sav', 'wb'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZqcxS0T30Hy",
        "colab_type": "text"
      },
      "source": [
        "# Manual tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9lPFswqIpwQ",
        "colab_type": "text"
      },
      "source": [
        "Finally, some final manual tests to check our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqoMifpvw23x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer_sav = pickle.load(open('vectorizer.sav', 'rb'))\n",
        "classifier_sav = pickle.load(open('classifier_regression.sav', 'rb'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V96Pi5YEk9Ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tests = [\"jojo todynho cancelada\",\n",
        "         \"jojo todynho chata\",\n",
        "         \"jojo todynho lenda\",\n",
        "         \"jojo todynho ícone\",\n",
        "         \"jojo todynho perfeita\",\n",
        "         \"jojo todynho rainha\"]\n",
        "freq_tests = vectorizer_sav.transform(tests)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG1-hhVQk5TZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "3d60c6d3-55a2-4b92-ec6b-16907800312d"
      },
      "source": [
        "for t, c in zip (tests, classifier_sav.predict(freq_tests)):\n",
        "    print (t +\", \"+ c) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jojo todynho cancelada, -1\n",
            "jojo todynho chata, -1\n",
            "jojo todynho lenda, 1\n",
            "jojo todynho ícone, 1\n",
            "jojo todynho perfeita, 1\n",
            "jojo todynho rainha, 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGqZfTUSLzl3",
        "colab_type": "text"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iADFLMbl7xeE",
        "colab_type": "text"
      },
      "source": [
        "BRUM, Henrico Bertini; NUNES, Maria das Graças Volpe. (2017). Building a sentiment corpus of tweets in brazilian portuguese. Available at: https://www.aclweb.org/anthology/L18-1658.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woR34vQPL3bc",
        "colab_type": "text"
      },
      "source": [
        "Gaurav Singhal Tutorial: https://www.pluralsight.com/guides/building-a-twitter-sentiment-analysis-in-python\n",
        "\n",
        "Felipe Santana Tutorial: https://minerandodados.com.br/analise-de-sentimentos-utilizando-dados-do-twitter/\n",
        "\n",
        "Best way to strip punctuation from a string https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
        "\n",
        "Which metrics to use: https://blog.infegy.com/understanding-sentiment-analysis-and-sentiment-accuracy\n",
        "\n",
        "Test Train vs. Cross Validation: https://medium.com/@eijaz/holdout-vs-cross-validation-in-machine-learning-7637112d3f8f"
      ]
    }
  ]
}